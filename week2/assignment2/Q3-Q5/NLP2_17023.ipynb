{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bIZnhJL_Lihx"
   },
   "source": [
    "NLP-ASSIGNMENT-2\n",
    "\n",
    "Abhinav Duvvuri\n",
    "\n",
    "AM.EN.U4CSE17023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "colab_type": "code",
    "id": "uaSVjDfG8K_F",
    "outputId": "4e1cc8dc-f3e8-4399-a239-447c70a380eb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /home/abhinav/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /home/abhinav/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /home/abhinav/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /home/abhinav/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /home/abhinav/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /home/abhinav/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /home/abhinav/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /home/abhinav/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /home/abhinav/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /home/abhinav/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /home/abhinav/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /home/abhinav/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /home/abhinav/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /home/abhinav/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /home/abhinav/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /home/abhinav/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /home/abhinav/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /home/abhinav/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /home/abhinav/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    " import nltk, re, pprint\n",
    " nltk.download('popular')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FrJkqNLy8bYw"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "file_1 = open('chatbot.txt',mode='r')\n",
    "tokens = []\n",
    "for line in file_1:\n",
    "  tokens.append(word_tokenize(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vtpE0TnR-BYy",
    "outputId": "1104e4f9-3397-4034-93ad-8e180358aa37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Since',\n",
       "  'chatbots',\n",
       "  'are',\n",
       "  'still',\n",
       "  'a',\n",
       "  'relatively',\n",
       "  'new',\n",
       "  'technology',\n",
       "  ',',\n",
       "  'there',\n",
       "  'is',\n",
       "  'debate',\n",
       "  'around',\n",
       "  'the',\n",
       "  'amount',\n",
       "  'and',\n",
       "  'classification',\n",
       "  'of',\n",
       "  'the',\n",
       "  'available',\n",
       "  'types',\n",
       "  '.',\n",
       "  'However',\n",
       "  ',',\n",
       "  'some',\n",
       "  'common',\n",
       "  'types',\n",
       "  'of',\n",
       "  'chatbots',\n",
       "  'include',\n",
       "  ':'],\n",
       " ['Scripted',\n",
       "  'or',\n",
       "  'quick',\n",
       "  'reply',\n",
       "  'chatbots',\n",
       "  '-',\n",
       "  'These',\n",
       "  'are',\n",
       "  'the',\n",
       "  'most',\n",
       "  'basic',\n",
       "  'chatbots',\n",
       "  ';',\n",
       "  'they',\n",
       "  'act',\n",
       "  'as',\n",
       "  'a',\n",
       "  'hierarchical',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  '.',\n",
       "  'These',\n",
       "  'bots',\n",
       "  'interact',\n",
       "  'with',\n",
       "  'users',\n",
       "  'through',\n",
       "  'a',\n",
       "  'set',\n",
       "  'of',\n",
       "  'predefined',\n",
       "  'questions',\n",
       "  'that',\n",
       "  'progress',\n",
       "  'until',\n",
       "  'the',\n",
       "  'chatbot',\n",
       "  'has',\n",
       "  'answered',\n",
       "  'the',\n",
       "  'user',\n",
       "  \"'s\",\n",
       "  'question',\n",
       "  '.',\n",
       "  'Similar',\n",
       "  'to',\n",
       "  'this',\n",
       "  'chatbot',\n",
       "  'is',\n",
       "  'the',\n",
       "  'menu-based',\n",
       "  'chatbot',\n",
       "  'that',\n",
       "  'requires',\n",
       "  'users',\n",
       "  'to',\n",
       "  'make',\n",
       "  'selections',\n",
       "  'from',\n",
       "  'a',\n",
       "  'predefined',\n",
       "  'list',\n",
       "  ',',\n",
       "  'or',\n",
       "  'menu',\n",
       "  ',',\n",
       "  'to',\n",
       "  'provide',\n",
       "  'the',\n",
       "  'bot',\n",
       "  'with',\n",
       "  'a',\n",
       "  'deeper',\n",
       "  'understanding',\n",
       "  'of',\n",
       "  'what',\n",
       "  'the',\n",
       "  'customer',\n",
       "  'is',\n",
       "  'looking',\n",
       "  'for',\n",
       "  '.'],\n",
       " ['Keyword',\n",
       "  'recognition-based',\n",
       "  'chatbots',\n",
       "  '-',\n",
       "  'These',\n",
       "  'chatbots',\n",
       "  'are',\n",
       "  'a',\n",
       "  'bit',\n",
       "  'more',\n",
       "  'complex',\n",
       "  ';',\n",
       "  'they',\n",
       "  'attempt',\n",
       "  'to',\n",
       "  'listen',\n",
       "  'to',\n",
       "  'what',\n",
       "  'the',\n",
       "  'user',\n",
       "  'types',\n",
       "  'and',\n",
       "  'respond',\n",
       "  'accordingly',\n",
       "  'using',\n",
       "  'keywords',\n",
       "  'picked',\n",
       "  'up',\n",
       "  'from',\n",
       "  'customer',\n",
       "  'responses',\n",
       "  '.',\n",
       "  'Customizable',\n",
       "  'key',\n",
       "  'words',\n",
       "  'and',\n",
       "  'AI',\n",
       "  'are',\n",
       "  'combined',\n",
       "  'in',\n",
       "  'this',\n",
       "  'bot',\n",
       "  'to',\n",
       "  'provide',\n",
       "  'an',\n",
       "  'appropriate',\n",
       "  'response',\n",
       "  'to',\n",
       "  'users',\n",
       "  '.',\n",
       "  'Unfortunately',\n",
       "  ',',\n",
       "  'these',\n",
       "  'chatbots',\n",
       "  'struggle',\n",
       "  'when',\n",
       "  'faced',\n",
       "  'with',\n",
       "  'repetitive',\n",
       "  'keyword',\n",
       "  'use',\n",
       "  'or',\n",
       "  'redundant',\n",
       "  'questions',\n",
       "  '.'],\n",
       " ['Hybrid',\n",
       "  'chatbots',\n",
       "  '-',\n",
       "  'These',\n",
       "  'chatbots',\n",
       "  'combine',\n",
       "  'elements',\n",
       "  'of',\n",
       "  'menu-based',\n",
       "  'and',\n",
       "  'keyword',\n",
       "  'recognition-based',\n",
       "  'bots',\n",
       "  '.',\n",
       "  'Users',\n",
       "  'can',\n",
       "  'choose',\n",
       "  'to',\n",
       "  'have',\n",
       "  'their',\n",
       "  'questions',\n",
       "  'answered',\n",
       "  'directly',\n",
       "  ',',\n",
       "  'but',\n",
       "  'can',\n",
       "  'also',\n",
       "  'access',\n",
       "  'the',\n",
       "  'chatbot',\n",
       "  \"'s\",\n",
       "  'menu',\n",
       "  'to',\n",
       "  'make',\n",
       "  'selections',\n",
       "  'if',\n",
       "  'the',\n",
       "  'keyword',\n",
       "  'recognition',\n",
       "  'process',\n",
       "  'produces',\n",
       "  'ineffective',\n",
       "  'results',\n",
       "  '.'],\n",
       " ['Contextual',\n",
       "  'chatbots',\n",
       "  '-',\n",
       "  'These',\n",
       "  'chatbots',\n",
       "  'are',\n",
       "  'more',\n",
       "  'complex',\n",
       "  'than',\n",
       "  'those',\n",
       "  'listed',\n",
       "  'above',\n",
       "  'and',\n",
       "  'require',\n",
       "  'a',\n",
       "  'data-centric',\n",
       "  'focus',\n",
       "  '.',\n",
       "  'They',\n",
       "  'use',\n",
       "  'ML',\n",
       "  'and',\n",
       "  'AI',\n",
       "  'to',\n",
       "  'remember',\n",
       "  'conversations',\n",
       "  'and',\n",
       "  'interactions',\n",
       "  'with',\n",
       "  'users',\n",
       "  ',',\n",
       "  'and',\n",
       "  'then',\n",
       "  'use',\n",
       "  'these',\n",
       "  'memories',\n",
       "  'to',\n",
       "  'grow',\n",
       "  'and',\n",
       "  'improve',\n",
       "  'over',\n",
       "  'time',\n",
       "  '.',\n",
       "  'Instead',\n",
       "  'of',\n",
       "  'relying',\n",
       "  'on',\n",
       "  'keywords',\n",
       "  ',',\n",
       "  'these',\n",
       "  'bots',\n",
       "  'use',\n",
       "  'what',\n",
       "  'customers',\n",
       "  'ask',\n",
       "  'for',\n",
       "  'and',\n",
       "  'how',\n",
       "  'they',\n",
       "  'ask',\n",
       "  'it',\n",
       "  'to',\n",
       "  'provide',\n",
       "  'answers',\n",
       "  'and',\n",
       "  'self-improve',\n",
       "  '.'],\n",
       " ['Voice-enabled',\n",
       "  'chatbots',\n",
       "  '-',\n",
       "  'This',\n",
       "  'type',\n",
       "  'of',\n",
       "  'chatbot',\n",
       "  'is',\n",
       "  'the',\n",
       "  'future',\n",
       "  'of',\n",
       "  'chatbot',\n",
       "  'technology',\n",
       "  '.',\n",
       "  'Voice-enabled',\n",
       "  'chatbots',\n",
       "  'use',\n",
       "  'spoken',\n",
       "  'dialogue',\n",
       "  'from',\n",
       "  'users',\n",
       "  'as',\n",
       "  'input',\n",
       "  'that',\n",
       "  'prompts',\n",
       "  'responses',\n",
       "  'or',\n",
       "  'creative',\n",
       "  'tasks',\n",
       "  '.',\n",
       "  'They',\n",
       "  'can',\n",
       "  'be',\n",
       "  'created',\n",
       "  'using',\n",
       "  'text-to-speech',\n",
       "  '(',\n",
       "  'TTS',\n",
       "  ')',\n",
       "  'and',\n",
       "  'voice',\n",
       "  'recognition',\n",
       "  'application',\n",
       "  'program',\n",
       "  'interfaces',\n",
       "  '(',\n",
       "  'APIs',\n",
       "  ')',\n",
       "  '.',\n",
       "  'Current',\n",
       "  'examples',\n",
       "  'include',\n",
       "  'Amazon',\n",
       "  'Alexa',\n",
       "  'and',\n",
       "  'Apple',\n",
       "  \"'s\",\n",
       "  'Siri',\n",
       "  '.'],\n",
       " ['Examples', 'of', 'chatbot', 'uses'],\n",
       " ['Chatbot',\n",
       "  'use',\n",
       "  'is',\n",
       "  'on',\n",
       "  'the',\n",
       "  'rise',\n",
       "  ',',\n",
       "  'both',\n",
       "  'in',\n",
       "  'the',\n",
       "  'business',\n",
       "  'and',\n",
       "  'consumer',\n",
       "  'markets',\n",
       "  '.',\n",
       "  'As',\n",
       "  'chatbots',\n",
       "  'improve',\n",
       "  ',',\n",
       "  'consumers',\n",
       "  'have',\n",
       "  'less',\n",
       "  'to',\n",
       "  'quarrel',\n",
       "  'about',\n",
       "  'while',\n",
       "  'interacting',\n",
       "  'with',\n",
       "  'them',\n",
       "  '.',\n",
       "  'Between',\n",
       "  'advanced',\n",
       "  'technology',\n",
       "  'and',\n",
       "  'a',\n",
       "  'societal',\n",
       "  'transition',\n",
       "  'to',\n",
       "  'more',\n",
       "  'passive',\n",
       "  ',',\n",
       "  'text-based',\n",
       "  'communication',\n",
       "  ',',\n",
       "  'chatbots',\n",
       "  'help',\n",
       "  'fill',\n",
       "  'a',\n",
       "  'niche',\n",
       "  'that',\n",
       "  'phone',\n",
       "  'calls',\n",
       "  'used',\n",
       "  'to',\n",
       "  'fill',\n",
       "  '.'],\n",
       " ['Chatbots',\n",
       "  'have',\n",
       "  'been',\n",
       "  'used',\n",
       "  'in',\n",
       "  'instant',\n",
       "  'messaging',\n",
       "  'applications',\n",
       "  'and',\n",
       "  'online',\n",
       "  'interactive',\n",
       "  'games',\n",
       "  'for',\n",
       "  'many',\n",
       "  'years',\n",
       "  ',',\n",
       "  'but',\n",
       "  'have',\n",
       "  'recently',\n",
       "  'segued',\n",
       "  'into',\n",
       "  'B2C',\n",
       "  'and',\n",
       "  'B2B',\n",
       "  'sales',\n",
       "  'and',\n",
       "  'services',\n",
       "  '.',\n",
       "  'Chatbots',\n",
       "  'can',\n",
       "  'be',\n",
       "  'added',\n",
       "  'to',\n",
       "  'a',\n",
       "  'buddy',\n",
       "  'list',\n",
       "  'or',\n",
       "  'provide',\n",
       "  'a',\n",
       "  'single',\n",
       "  'game',\n",
       "  'player',\n",
       "  'with',\n",
       "  'an',\n",
       "  'entity',\n",
       "  'to',\n",
       "  'interact',\n",
       "  'with',\n",
       "  'while',\n",
       "  'awaiting',\n",
       "  'other',\n",
       "  '``',\n",
       "  'live',\n",
       "  \"''\",\n",
       "  'players',\n",
       "  '.',\n",
       "  'If',\n",
       "  'the',\n",
       "  'bot',\n",
       "  'is',\n",
       "  'sophisticated',\n",
       "  'enough',\n",
       "  'to',\n",
       "  'pass',\n",
       "  'the',\n",
       "  'Turing',\n",
       "  'test',\n",
       "  ',',\n",
       "  'the',\n",
       "  'person',\n",
       "  'may',\n",
       "  'not',\n",
       "  'even',\n",
       "  'know',\n",
       "  'they',\n",
       "  'are',\n",
       "  'interacting',\n",
       "  'with',\n",
       "  'a',\n",
       "  'computer',\n",
       "  'program',\n",
       "  '.'],\n",
       " ['In',\n",
       "  'sales',\n",
       "  ',',\n",
       "  'chatbots',\n",
       "  'are',\n",
       "  'being',\n",
       "  'used',\n",
       "  'to',\n",
       "  'assist',\n",
       "  'consumers',\n",
       "  'shopping',\n",
       "  'online',\n",
       "  ',',\n",
       "  'either',\n",
       "  'by',\n",
       "  'answering',\n",
       "  'noncomplex',\n",
       "  'product',\n",
       "  'questions',\n",
       "  'or',\n",
       "  'providing',\n",
       "  'helpful',\n",
       "  'information',\n",
       "  'that',\n",
       "  'the',\n",
       "  'consumer',\n",
       "  'could',\n",
       "  'later',\n",
       "  'search',\n",
       "  'for',\n",
       "  ',',\n",
       "  'including',\n",
       "  'shipping',\n",
       "  'price',\n",
       "  'and',\n",
       "  'availability',\n",
       "  '.',\n",
       "  'Chatbots',\n",
       "  'are',\n",
       "  'also',\n",
       "  'used',\n",
       "  'in',\n",
       "  'service',\n",
       "  'departments',\n",
       "  ',',\n",
       "  'assisting',\n",
       "  'service',\n",
       "  'agents',\n",
       "  'in',\n",
       "  'answering',\n",
       "  'repetitive',\n",
       "  'requests',\n",
       "  '.',\n",
       "  'Once',\n",
       "  'a',\n",
       "  'conversation',\n",
       "  'gets',\n",
       "  'too',\n",
       "  'complex',\n",
       "  'for',\n",
       "  'a',\n",
       "  'chatbot',\n",
       "  ',',\n",
       "  'it',\n",
       "  'will',\n",
       "  'be',\n",
       "  'transferred',\n",
       "  'to',\n",
       "  'a',\n",
       "  'human',\n",
       "  'service',\n",
       "  'agent',\n",
       "  '.'],\n",
       " ['Chatbots',\n",
       "  'are',\n",
       "  'also',\n",
       "  'used',\n",
       "  'as',\n",
       "  'virtual',\n",
       "  'assistants',\n",
       "  '.',\n",
       "  'Apple',\n",
       "  ',',\n",
       "  'Amazon',\n",
       "  ',',\n",
       "  'Google',\n",
       "  'and',\n",
       "  'Microsoft',\n",
       "  'all',\n",
       "  'have',\n",
       "  'forms',\n",
       "  'of',\n",
       "  'virtual',\n",
       "  'assistants',\n",
       "  '.',\n",
       "  'Apps',\n",
       "  ',',\n",
       "  'such',\n",
       "  'as',\n",
       "  'Apple',\n",
       "  \"'s\",\n",
       "  'Siri',\n",
       "  'and',\n",
       "  'Microsoft',\n",
       "  \"'s\",\n",
       "  'Cortana',\n",
       "  ',',\n",
       "  'or',\n",
       "  'products',\n",
       "  ',',\n",
       "  'like',\n",
       "  'Amazon',\n",
       "  \"'s\",\n",
       "  'Echo',\n",
       "  'with',\n",
       "  'Alexa',\n",
       "  'or',\n",
       "  'Google',\n",
       "  'Home',\n",
       "  ',',\n",
       "  'all',\n",
       "  'play',\n",
       "  'the',\n",
       "  'part',\n",
       "  'of',\n",
       "  'a',\n",
       "  'personal',\n",
       "  'chatbot',\n",
       "  '.']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCE05x8S-IUl"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "default_stopwords = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yh4_9A63JAgM"
   },
   "outputs": [],
   "source": [
    "tt = [inner for outer in tokens for inner in outer]\n",
    "tt = [word.lower() for word in tt if len(word) > 3]\n",
    "tt = [word for word in tt if word not in default_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "colab_type": "code",
    "id": "4IFUsqmY-igU",
    "outputId": "9fed3902-7657-49c2-c0d3-8850ccfa275e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatbots;20\n",
      "chatbot;10\n",
      "users;6\n",
      "used;5\n",
      "questions;4\n",
      "provide;4\n",
      "keyword;4\n",
      "technology;3\n",
      "types;3\n",
      "bots;3\n"
     ]
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(tt)\n",
    "for word, frequency in fdist.most_common(10):\n",
    "    print(u'{};{}'.format(word, frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "colab_type": "code",
    "id": "BlLDk4ZYIQ91",
    "outputId": "a0fa4f87-4aa0-4b94-8c78-c5e04a60046a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatbots  :  chatbot\n",
      "chatbot  :  chatbot\n",
      "users  :  user\n",
      "used  :  use\n",
      "questions  :  question\n",
      "provide  :  provid\n",
      "keyword  :  keyword\n",
      "technology  :  technolog\n",
      "types  :  type\n",
      "bots  :  bot\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "stems = []\n",
    "for word,frequency in fdist.most_common(10):\n",
    "  print(word, \" : \", ps.stem(word))\n",
    "  stems.append(ps.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "colab_type": "code",
    "id": "mFQ05t-rJBvq",
    "outputId": "eb1b62b1-63b9-4d72-c3a0-d7f8ad81415b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatbots  :  chatbots\n",
      "chatbot  :  chatbot\n",
      "users  :  user\n",
      "used  :  used\n",
      "questions  :  question\n",
      "provide  :  provide\n",
      "keyword  :  keyword\n",
      "technology  :  technology\n",
      "types  :  type\n",
      "bots  :  bot\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lem = []\n",
    "\n",
    "for word,frequency in fdist.most_common(10):\n",
    "  print(word, \" : \", lemmatizer.lemmatize(word))\n",
    "  lem.append(lemmatizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "bArLQlXCJwq5",
    "outputId": "e363ddef-5236-45ae-feba-ce56823e964c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Stemmed word:  chatbots  || Stemmed Word chatbot\n",
      "Not Stemmed word:  users  || Stemmed Word user\n",
      "Not Stemmed word:  used  || Stemmed Word use\n",
      "Not Stemmed word:  questions  || Stemmed Word question\n",
      "Not Stemmed word:  provide  || Stemmed Word provid\n",
      "Not Stemmed word:  technology  || Stemmed Word technolog\n",
      "Not Stemmed word:  types  || Stemmed Word type\n",
      "Not Stemmed word:  bots  || Stemmed Word bot\n"
     ]
    }
   ],
   "source": [
    "x = fdist.most_common(10)\n",
    "for i in range(len(stems)):\n",
    "  if stems[i] != x[i][0]:\n",
    "    print(\"Not Stemmed word: \", x[i][0], \" || Stemmed Word\", stems[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "aqGu4cw6K0Cl",
    "outputId": "6bb8c81f-984a-4700-a3c9-b868203aa02c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Lemmatized word:  users  || Lemmatized Word user\n",
      "Not Lemmatized word:  questions  || Lemmatized Word question\n",
      "Not Lemmatized word:  types  || Lemmatized Word type\n",
      "Not Lemmatized word:  bots  || Lemmatized Word bot\n"
     ]
    }
   ],
   "source": [
    "x = fdist.most_common(10)\n",
    "for i in range(len(lem)):\n",
    "  if lem[i] != x[i][0]:\n",
    "    print(\"Not Lemmatized word: \", x[i][0], \" || Lemmatized Word\", lem[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "08UxWqCjLQWE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "17053_NLP2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
